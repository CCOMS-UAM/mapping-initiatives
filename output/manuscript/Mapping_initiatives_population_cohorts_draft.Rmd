---
title: |
  Mapping of initiatives that integrate european and
  international population cohorts
output:
  officedown::rdocx_document:
    base_format:     bookdown::word_document2
    reference_docx:  ../www/APA_6th_edition_template.docx
    fig_width:       6.73
    fig_asp:          .75
    number_sections: no
    tables:
      layout:        autofit
      caption:
        sep: '. '
    keep_md:         no
bibliography:        ../www/Mapping_initiatives.bib
csl:                 ../www/apa-old-doi-prefix.csl
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Environment setup:

gc()

# Libraries:
library(knitr)
library(tidyverse)
library(readxl)
library(vctrs)
library(gtsummary)
library(flextable)
library(ftExtra)
library(rlang)
library(countrycode)
library(english)
library(magrittr)
library(scales)

# Constants:
DOC_DIR      <- getwd()
ROOT_DIR     <- ".."
SRC_DIR      <- "src"
SRC_FILEPATH <- file.path(SRC_DIR, "<TODO: Complete when necessary>.R")

# Knitr configuration:

opts_knit$set(root.dir = ROOT_DIR) # Interferes with officedown!
opts_chunk$set(
  echo       = FALSE,
  results    = 'hide',
  message    = FALSE,
  warning    = FALSE,
  cache      = TRUE,
  autodep    = TRUE,
  dpi        = 300,
  fig.retina = 1,
  tab.topcaption = TRUE,
  dev.args   = list(png = list(type = "cairo"))
)


# Output formatting options:

theme_gtsummary_compact()
# theme_gtsummary_printer(print_engine = "flextable")

set_flextable_defaults(
  font.family = "Times New Roman",
  post_process_docx = theme_booktabs
)
```

```{r includes}
source("R/Constants.R", encoding = 'UTF-8')
source("R/Output.R", encoding = 'UTF-8')
```

```{r load-chunks, cache=FALSE}
## TODO: Evaluate if necessary
# SRC_FILEPATH %>% read_chunk()
```

# Introduction

The amount of scientific data is rapidly increasing [@shilo_axes_2020].
In the healthcare domain, about 500 petabytes (10^15^ bytes)
were produced in 2012,
while the estimate for 2020 was between 25,000 petabytes and
16 zettabytes [16 trillion GB, @cavanillas_new_2016; @roski_creating_2014].
Other sectors also parallel such increase
--finance and insurance, energy and transportation, media and entertainment,
or the public sector [@hulsen_big_2019].
This massive amount of available information,
occasionally referred to as "the new oil" [@cavanillas_new_2016],
provides great opportunities to improve decision-making, reduce costs,
and extract meaningful information.
These in turn would help develop further the different pathways
of personalized medicine.

The pressure to develop new strategies to integrate and organize
all this information is rapidly building up,
in order to get the most out of such a valuable resource.
However, the potential benefits have not been optimally exploited
due to methodological and infrastructure issues
when integrating these data [@panahiazar_empowering_2014].
Also, concerns about data protection as well as legal and ethical aspects
are changing the landscape, adding new constraints that cannot be overlooked.

Europe is one of the largest providers of research
[@noauthor_2019_nodate],
with several country members involved in large-scale cohort studies
(e.g., Millennium Cohort Study;
Environmental Health Risks in European Birth Cohorts,
Collaborative Research on Ageing in Europe,
English Longitudinal Study of Ageing).
SYNCHROS (SYNergies for Cohorts in Health:
integrating the Role of all Stakeholders),
a Europe-wide project funded by the Horizon 2020 Research Program,
has been created with these challenges in mind (https://synchros.eu).
The main objective of its coordination and support action
is to establish a sustainable European strategy for the development of
the next generation of integrated cohorts,
using consensus-based implementation science tools.
Subsequently, it aims to contributing to an international strategic agenda for
a global, enhanced coordination of cohorts, in order to address the practical,
ethical, legal, and methodological challenges of optimizing
the exploitation of past and future cohort data.
In order to pursue its aim, the SYNCHROS partners are
(i) mapping the cohort landscape in Europe and world-wide international cohort
integration initiatives;
(ii) compiling the different methodologies for integrating cohort data;
(iii) recognizing solutions for practical, ethical, and legal challenges in
harmonizing information from patients, clinical trial, and population cohorts;
and (iv) assessing new data collection technologies and new types of data.
With the first of these goals in mind, our objective here is to report
the state of the art in the integration of population cohorts.
We do so by gathering a collection of initiatives that have integrated
such cohorts in the last twenty years,
internationally and in Europe in particular.

# Methods

## Identification of initiatives

In order to find initiatives that integrate population cohorts,
three different methods were used.
The first was a systematic search in the MEDLINE database.
The second were candidate initiatives suggested by the SYNCHROS
consortium partners.
The third was a descendent search using the information
(references, descriptions, and links) from the two previous sources.

## Database search in MEDLINE

The search terms applied tried to cover the objectives of the SYNCHROS project
and produce a representative, rather than exhaustive, list of initiatives.
These terms were selected and agreed upon by a consensus among
the consortium partners.
The terms that provided less than 500 hits were kept. New terms for use in
follow-up searches were then extracted from their abstracts.
The term "cohort" was included in some searches,
in order to limit the number of hits.  
The final search query was:

```
(cohort OR “prospective study” OR
  “longitudinal study” OR
  "individual meta-analysis"[All Fields] OR
  "individual participant data meta-analysis"[All Fields] OR
  "individual patient data meta-analysis"[All Fields] OR
  "individual meta analysis"[All Fields] OR
  "individual participant data meta analysis"[All Fields] OR
  "individual patient data meta analysis"[All Fields] OR
  "meta analysis using individual"[All Fields] OR
  "meta-analysis using individual"[All Fields] OR
  "meta analysis of individual"[All Fields] OR
  "meta-analysis of individual"[All Fields] OR
  "mega-analysis"[All Fields] OR
  "mega analysis"[All Fields])  
AND  
("harmonization study" OR
  "integration study" OR
  "integration initiative" OR
  "integrated study" OR
  "merged cohort" OR
  "data pooling" OR
  "pooled sample" OR
  "combined data" OR
  "combining data" OR
  "harmonized data" OR
  "harmonised data" OR
  "harmonizing data" OR
  "data harmonization" OR
  "data harmonisation" OR
  "data sharing" OR
  "common database" OR
  "multiple cohorts" OR
  "multiple longitudinal studies" OR
  "international consortium" OR
  "collaborative effort").  
AND  
("2000/01/01"[Date - Publication] : "2019/07/31"[Date - Publication])  
AND  
English[Language]  
AND  
Humans[MeSH]
```

## Selection of initiatives

**Inclusion criteria.** Initiatives published in English from 2000 to july 2019
were included if they integrated health population cohorts of any age
(birth, adolescents, adults, elderly, oldest old),
and included sociodemographic, lifestyle, biological, genetic, omics
(genomics, proteomics, metabolomics), imaging, or environment factors data.
Face-to-face, online, or ICT assessments were included.
Additionally, at least one cohort included in the initiative had to
have information about the sample at two or more time points.

**Exclusion criteria.** Initiatives without available data about (or access to)
their descriptive information (webpage, a main report describing the main aim(s)
in detail) were excluded.
Initiatives that integrated clinical trial cohorts and/or patient cohorts were
are the subject of another publication [@rodriguez-laso_map_2021]
and thus were also excluded.

For all the initiatives found, a double-check was performed by
two different researchers in order to carry out an objective evaluation and
reducing the risk of bias.
In case of discrepancy between the two reviewers, a third person was consulted.

## Data extraction and analysis

The following technical information was extracted from the initiatives:
name, principal investigator (PI), initiative partners,
region(s)/country/ies included,
name of the institution responsible for the initiative, funding resources,
contact person, information source, whether the research team of
the initiative was active at the time of consultation, main objectives,
criteria for the cohorts to be included,
type of harmonization (prospective/retrospective),
number of cohorts included (total number and number of harmonized cohorts),
whether more cohorts were foreseen to be harmonized,
number of participants (total number, and number of participants with
harmonized data), age range of the sample,
maximum number of variables that had been harmonized
(including those where harmonization was not possible for all the cohorts),
setting of the harmonized cohorts (local-regional/national/international),
countries and research topics addressed,
and a brief description of the population addressed. When the information
was not available through the website or published articles,
the principal investigator and/or the contact person of the project
was consulted, by email first and, if no reply was received,
by telephone or postal mail. Descriptive statistics were computed for this
information (absolute frequencies and proportions for the categorical variables,
and median, minimum, and maximum for the quantitative ones).
In the case of the number of participants with harmonized data and
the maximum number of harmonized variables, the descriptives were computed
only using the initiatives that had harmonized cohorts.

# Results

```{r load-data}
# N.B.: Correspondence with the generating dataset
#   (see `notebooks/Update_initiatives.Rmd` and
#   `notebooks/Complete_initiatives_additional`, result is stored in object
#   `mica_data_complete` and `initiatives_complete`, respectively)
#   has been checked. The differences are due to trailing whitespaces and
#   end of line (\n) characters, which are trimmed off when
#   reading with `readxl::read_excel()`.

tab1_new <- read_excel(INITIATIVES_FILEPATH, sheet = COMPLETE_TABLE_SHEET)

# Cast to proper vector types (easier than specifying all column types above):
tab1_new <- tab1_new |> mutate(
  across(
    methodology.moreCohortsToBeHarmonized,
    factor,
    levels = c("FALSE", "TRUE"),
    labels = c("No", "Yes")
  )
)

# Simplify variable names
tab1_new <- tab1_new |>
  rename_with(str_remove, pattern = "methodology.") |>
  rename_with(str_remove, pattern = "nb")           |>
  rename_with(tolower)

# Reorder variables (the ones to the output first, then the rest)
tab1_new <- tab1_new |> select(
  initiative,
  region_countries,
  description:participants.harmonized,
  age_range,
  harmonizedvariables,
  cohortcriteria,
  everything()
)
```

```{r country-derivate-vars}
# Create variable counts derivated from the countries variable
tab1_continents <- tab1_new                    |>
  separate_rows(countries, sep = COMMA_SEP)    |>
  select(id, countries)                        |>
  drop_na()                                    |>
  mutate(
    continent   = countries |>
      countrycode(origin = "country.name", destination = "continent")
  )                                            |>
  count(id, continent)                         |>
  complete(id, continent, fill = list(n = 0L)) |>
  mutate(bool = n |> as.logical())

# Complete missing values with available information in `region`:

## Create dataset with existing information (with missing nº of countries where
##   necessary):
suppressWarnings( # Warning when converting countries in `region` to `continent`
  tab1_missing_countries <- tab1_new              |>
    select(id, region)                            |>
    anti_join(tab1_continents, by = "id")         |>
    drop_na()                                     |>
    separate_rows(region, sep = ENUM_SEPS_REGEXP) |>
    mutate(
      region    = region |> str_replace("American?", "Americas"),
      # Correct values
      continent = region |>
        countrycode(origin = "country.name", destination = "continent"),
      n         = region    |>
        str_extract("\\d+") |>
        as.integer()        |>
        coalesce(continent |> is.na() |> if_else(NA_integer_, 1L)),
      continent = continent |> coalesce(
        region |> str_extract(
          VECTOR_CONTINENTS |> glue_collapse(sep = '|') |> enclose('(')
        )
      ),
      bool      = continent != TRUE # Turns all non-missing to `TRUE`
    )                                             |>
    select(-region)
)

## Complete non-present information with proper values, and overwrite the
##   "known missings":
tab1_missing_countries <- tab1_missing_countries             |>
  complete(id, continent, fill = list(n = 0L, bool = FALSE)) |>
  rows_update(tab1_missing_countries, by = c("id", "continent"))

tab1_continents <- tab1_continents  |>
  bind_rows(tab1_missing_countries) |>
  group_by(id)                      |>
  add_count(wt = bool, name = "n_continents")

tab1_continents_wide <- tab1_continents |>
  ungroup()                             |>
  pivot_wider(names_from = continent, values_from = n:bool)

tab1_new <- tab1_new |> left_join(tab1_continents_wide, by = "id")
```

```{r wbdi-regions, eval=FALSE}
# Create variable counts derivated from the countries variable
tab1_regions <- tab1_new                         |>
  separate_rows(countries, sep = COMMA_SEP)      |>
  select(id, countries)                          |>
  drop_na()                                      |>
  mutate(
    wbdi_region = countries |>
      countrycode(origin = "country.name", destination = "region")
  )                                              |>
  count(id, wbdi_region)                         |>
  complete(id, wbdi_region, fill = list(n = 0L)) |>
  mutate(bool = n |> as.logical())

# Complete missing values with available information in `region`:

## Create dataset with existing information (with missing nº of countries where
##   necessary):
suppressWarnings( # Warning when converting countries in `region` to `continent`
  tab1_missing_countries <- tab1_new              |>
    select(id, region)                            |>
    anti_join(tab1_regions, by = "id")            |>
    drop_na()                                     |>
    separate_rows(region, sep = ENUM_SEPS_REGEXP) |>
    mutate(
      region    = region |> str_replace("American?", "Americas"),
      # Correct values
      wbdi_region = region |>
        countrycode(origin = "country.name", destination = "region"),
      n         = region    |>
        str_extract("\\d+") |>
        as.integer()        |>
        coalesce(wbdi_region |> is.na() |> if_else(NA_integer_, 1L)),
      wbdi_region = wbdi_region |> coalesce(
        region |> str_extract(
          VECTOR_REGIONS |> glue_collapse(sep = '|') |> enclose('(')
        )
      ),
      wbdi_region = (region == "Oceania") |> if_else(
        true  = "East Asia & Pacific",
        false = wbdi_region
      ),
      bool      = wbdi_region != TRUE # Turns all non-missing to `TRUE`
    )                                             |>
    select(-region)
)

## Complete non-present information with proper values, and overwrite the
##   "known missings":
tab1_missing_countries <- tab1_missing_countries |>
  drop_na(wbdi_region)                           |>
  mutate(wbdi_region = wbdi_region |> factor(levels = VECTOR_REGIONS))

tab1_missing_countries <- tab1_missing_countries               |>
  complete(id, wbdi_region, fill = list(n = 0L, bool = FALSE)) |>
  rows_update(tab1_missing_countries, by = c("id", "wbdi_region"))

tab1_regions <- tab1_regions        |>
  bind_rows(tab1_missing_countries) |>
  group_by(id)                      |>
  add_count(wt = bool, name = "n_wbdi_regions")

tab1_regions_wide <- tab1_regions |>
  ungroup()                             |>
  pivot_wider(names_from = wbdi_region, values_from = n:bool)

tab1_new <- tab1_new |> left_join(tab1_regions_wide, by = "id")
```

```{r health-topic-derivate-vars}
tab1_topics <- tab1_new                   |>
  separate_rows(healthtopic, sep = '\\|') |>
  select(id, healthtopic)

tab1_topic_headers <- tab1_topics |>
  drop_na()                       |>
  distinct(healthtopic)           |>
  transmute(
    var_name  = healthtopic,
    header      = "Topic",
    subheader = healthtopic                             |>
      str_replace(
        pattern     = "birth_infancy_childhood_health",
        replacement = "Birth, infancy & childhood health"
      )                                                 |>
      str_replace_all(pattern = '_', replacement = ' ') |>
      str_to_sentence()
  )

tab1_topics <- tab1_topics                              |>
  mutate(value = TRUE)                                  |>
  complete(id, healthtopic, fill = list(value = FALSE)) |>
  drop_na()                                             |>
  pivot_wider(names_from  = healthtopic, values_from = value)
```

```{r create-output-dataset}
# Create formatted output table for the initiatives table:
tab1_new_out <- tab1_new |> select(initiative:cohortcriteria)
```

```{r preprocess-descriptives}
# Initiatives without harmonized cohorts are assigned a "missing" value
#   to the number of harmonized variables and participants, so we can have
#   those descriptives for the actual initiatives with harmonized cohorts
tab1_new <- tab1_new |> mutate(
  across(
    c(participants.harmonized, harmonizedvariables),
    if_else, condition = cohorts.harmonized != 0, false = NA_real_
  )
)
```

```{r create-headers-labels}
# Get the names from the first two rows of the file, and create names and labels
suppressMessages( # Message when reading empty column names
  tab1_headers <- read_excel(
    INITIATIVES_FILEPATH,
    sheet = TABLE_1_SHEET,
    n_max = 1
  )                                                                          |>
    pivot_longer(everything(), names_to = "header", values_to = "subheader") |>
    mutate(
      header = header                            |>
        str_detect(AUTO_VARNAME_PREFIX_REGEXP)   |>
        if_else(header |> dplyr::lag(1), header) |>
        str_replace("harmonized", "harmonised"), # Correct errata in headers:
    )                                                                        |>
    mutate( # Edit headers to correspond to the new structure:
      header    = if_else(header == "INITIATIVE", "Initiative", header),
      header    = if_else(
        header == "Region, Country",
        true  = "Region / countries",
        false = header
      ),
      header    = if_else(header == "Main objective", "Description", header),
      header    = if_else(
        header |> str_detect("^Briefly"),
        true  = "Cohort criteria",
        false = header
      )
    )                                                                        |>
    # Delete unnecessary headers
    slice(-10)                                                               |>
    bind_rows( # Add additional labels for descriptives table
      tibble(
        header    = c(
          "Age"             |> rep(2),
          "Nº of countries",# n_countries
          "Nº of regions",  # n_continents
          "Nº of countries" |> rep(5),
          "Region"          |> rep(5)
        ),
        subheader = c(
          "Minimum", "Maximum",
          NA_character_     |> rep(2), # Total countries and continents
          VECTOR_CONTINENTS |> rep(2) # Continents (nº countries and boolean)
        )
      )
    )                                                                        |>
    add_column( # Add variable names column
      var_name = colnames(
        tab1_new |> select(-(id:region), -countries, -healthtopic)
      )
    )
)

# Add health topic variables and headers/labels
tab1_new <- tab1_new |> left_join(tab1_topics, by = "id")

tab1_headers <- tab1_headers |> bind_rows(tab1_topic_headers)

# Create labels and format subheaders:
tab1_headers <- tab1_headers |>
  unite(# TODO; Use subheaders as labels (when adding headers to the desc. tab.)
    header, subheader,
    col    = "label",
    sep    = COLON,
    remove = FALSE,
    na.rm  = TRUE
  )                          |>
  mutate( # Set duplicates for cell merging
    subheader = subheader |>
      is.na()             |>
      if_else(true = header, false = subheader)
  )

# Assign meaningful labels to columns
tab1_new <- tab1_new |> imap_dfc(# Labels to assign to the columns
  \(column, variable) {
    
    properties <- tab1_headers |> filter(var_name == variable)
    
    column %@% "header"     <- properties |> pull(header)
    column %@% "label"      <- properties |> pull(label)
    column %@% "subheader"  <- properties |> pull(subheader)
    # TODO: Substituted two previous lines by the follwing:
    # column %@% "label"  <- properties |> pull(subheader)
    
    column
  }
)
```

```{r set-flextable-wd, cache=FALSE}
# Necessary for flextable to find the csl file:
opts_knit$set(root.dir = DOC_DIR)
```

```{r initiatives-table-outputs}
initiatives_table_output <- tab1_new_out                  |>
  flextable()                                             |>
  set_header_df(
    mapping = tab1_headers |> select(-label),
    key     = "var_name"
  )                                                       |>
  merge_h(part = "header")                                |>
  merge_v(part = "header")                                |>
  colformat_md(description)                               |>
  set_table_properties(layout = "autofit")
```

```{r descriptive-table}
tab1_new_describe <- tab1_new |> select(
  -where(is.character),
  -matches("^n_[A-Z]", ignore.case = FALSE)
)

descriptives_table_output <- tab1_new_describe |> tbl_summary(
  statistic    = list(all_continuous() ~ "{median} ({min} - {max})"),
  digits       = list(all_categorical() ~ c(0, 1)),
  missing_text = "(Missing)"
  # sort = # TODO: Does not seem to work
)
```

```{r descriptive-values, cache=FALSE}
# Total nº of initiatives:
total_N_out <- descriptives_table_output |> extract2("N") |> as.english()

# Maximum number of missing values in one descriptive variable:
max_missing_out <- tab1_new_out                |>
  summarize(across(.fns = ~sum(is.na(.))/n())) |>
  pivot_longer(everything())                   |>
  filter(value == max(value))                  |>
  distinct(value)                              |>
  pull()                                       |>
  percent(accuracy = .1)

# Total nº of cohorts:
total_cohorts_range_out  <- descriptives_table_output |>
  inline_text(variable = "cohorts.total", pattern = "{min} and {max}")
total_cohorts_median_out <- descriptives_table_output |>
  inline_text(variable = "cohorts.total", pattern = "{median}")

# Harmonized cohorts:
harm_cohorts_max_out <- descriptives_table_output |>
  inline_text(variable = "cohorts.harmonized", pattern = "{max}")

# More cohorts to be harmonized:
more_cohorts_expected_out <- descriptives_table_output |>
  inline_text(variable = "morecohortstobeharmonized", pattern = "{n}")

# Harmonized variables:
harm_vars_range_out  <- descriptives_table_output |>
  inline_text(variable = "harmonizedvariables", pattern = "{min} to {max}")
harm_vars_median_out <- descriptives_table_output |>
  inline_text(variable = "harmonizedvariables", pattern = "{median}")

# Harmonized participants:
harm_participants_max_out    <- descriptives_table_output |>
  inline_text(variable = "participants.harmonized", pattern = "{max}")
harm_participants_median_out <- descriptives_table_output |>
  inline_text(variable = "participants.harmonized", pattern = "{median}")

# Particinats' ages across included cohorts:
max_age_max_out  <- descriptives_table_output |>
  inline_text(variable = "age.max", pattern = "{max}")

# Topics:
prop_Ageing_out <- descriptives_table_output |>
  inline_text(variable = "ageing", pattern = "{p}%")

# Nº of countries:
max_n_countries_out <- descriptives_table_output           |>
  inline_text(variable = "n_countries", pattern = "{max}") |>
  as.integer()                                             |>
  as.english()
min_n_countries_out <- descriptives_table_output           |>
  inline_text(variable = "n_countries", pattern = "{min}") |>
  as.integer()                                             |>
  as.english()

# Nº of continents
prop_1_continent_out  <- descriptives_table_output |>
  inline_text(variable = "n_continents", level = "1", pattern = "{p}%")
prop_5_continents_out <- descriptives_table_output |>
  inline_text(variable = "n_continents", level = "5", pattern = "{p}%")

# Nº of initiatives per region
prop_Europe_out <- descriptives_table_output |>
  inline_text(variable = "bool_Europe", pattern = "{p}%")

n_Africa_out    <- descriptives_table_output             |>
  inline_text(variable = "bool_Africa", pattern = "{n}") |>
  as.integer()                                           |>
  as.english()
prop_Africa_out <- descriptives_table_output |>
  inline_text(variable = "bool_Africa", pattern = "{p}%")
```

The flowchart diagram in Figure 1 summarizes the initiatives
included and excluded using the three methods.
The MEDLINE search identified 843 articles that describe initiatives
to be potentially included. After screening the titles and abstracts,
the number of articles that met the inclusion criteria was cut down to 166.
From the full-text review, 155 articles were excluded due to one or more of
the following reasons: one-time efforts (articles where the merging of data
was done only for carrying out the research presented in the paper),
initiatives already submitted by partners, articles with
cross-sectional harmonization only, multisite cohorts/harmonization of waves,
meta-analyses, reviews, case control studies, patients' cohorts,
clinical trial cohorts, and others.
In total, 11 articles were retrieved from the systematic review.
Additionally, from the partners’ suggestions and the descendent searches,
189 potential initiatives were obtained. After screening for eligibility,
141 projects were excluded for one or more of the following reasons:
initiatives published before the year 2000,
projects that did not integrate cohorts,
and one initiative with only cross-sectional cohorts.
Forty-eight initiatives that integrate population cohorts were finally included.


<!-- A total of `r total_N_out` initiatives that integrate population cohorts
were identified. -->

The initiatives are presented in \@ref(tab:initiatives),
along with a subset of their most representative information.
It is worth noting that in a large amount of cases the contact person was
unreachable throughout the whole mapping process,
so the proportion of missing data was as large as
`r max_missing_out` for some properties.
The complete descriptive information of each initiative can be consulted
in the repository of the SYNCHROS project (www.synchros.eu).

The number of harmonized cohorts ranged between `r total_cohorts_range_out`
(median = `r total_cohorts_median_out`).
Some initiatives had as much as `r harm_cohorts_max_out` harmonized cohorts,
while others had harmonized cohorts at all.
However, at least `r more_cohorts_expected_out` initiatives expected
to harmonize more cohorts in the future.
The harmonized cohorts had a large variability in the maximum number of
harmonized variables, ranging from `r harm_vars_range_out`
(median = `r harm_vars_median_out`).
They would comprise as much as `r harm_participants_max_out` participants,
although the median value was around `r harm_participants_median_out`.

<br>

The targeted populations ranged in age from childbirth to as much as
`r max_age_max_out` (although this probably refers to an unbounded upper limit).
Ageing was the most prevalent topic,
addressed by a `r prop_Ageing_out` of the initiatives.
The cohorts comprised as much as `r max_n_countries_out`,
although there were also initiatives with cohorts from
only `r min_n_countries_out` country.
Most of them (`r prop_1_continent_out`) were circumscribed
to just one continent,
being Europe the most frequent (`r prop_Europe_out`),
while only a `r prop_5_continents_out` comprised cohorts from all
the five continents.
Africa was the most underrepresented continent,
with only `r n_Africa_out` initiatives (`r prop_Africa_out`) including cohorts
from it.
The complete descriptive information of the initiatives can be found in
\@ref(tab:descriptives).

# Discussion

The purpose of this mapping was to gather knowledge about the state of art of
the initiatives that integrate population cohorts.
The landscape of these initiatives has revealed to be quite disparate,
with a high variability of populations and variables as well as topics and
regions addressed by the integrated cohorts.

Interestingly, very few of the initiatives included cohorts focused on Africa.
Previous studies emphasize the relative lack of health studies conducted in
low- and middle-income countries [LMICs, @lawlor_birth_2009].
For instance, the most part of birth cohort studies [@victora_cohorts_2012]
are conducted in high-income countries, where annual births only amount to a 10%
of the births in LMICs. Among other factors, this may be due to
the relative less number of health investigators in LMICs
(40 times less on average; One Year on, Global Observatory on Health R&D
Identifies Striking Gaps and Inequalities, 2018).
Limitations in their national health and surveillance systems may also
hinder their capacity to reliably process health information
[@cash-gibson_inequalities_2018+. Whatever the reason, more representativeness
of LMICs will be necessary to grant the external validity of
the cohort studies that inform global health policy recommendations.

## Strengths and weaknesses

To our knowledge, this is the first effort to map and describe in detail all
the initiatives integrating population cohorts. Given the difficulties reported
by authors when integrating cohorts [@gatz_data_2015],
we expect that our results are helpful in three ways:
Firstly, identifying the barriers researches find when integrating
the different cohort studies.
Secondly, guiding the search for existing projects with harmonized cohorts.
And thirdly, providing guidelines for future projects aimed at integrating and
harmonizing cohorts.

Nevertheless, we must raise awareness on the non exhaustive nature of
this mapping. Given the big amount of population cohort studies published,
this manuscript aims at representativeness rather than exhaustiveness.
Also, as the response rate of the principal investigators was rather low,
relevant information of some initiatives is still missing.
However, the Synchros repository is an evolving project,
where the most recent information available is continuously updated.

## Conclusions

The promotion of interdisciplinary collaborations, with the aim of developing
and enriching a "learning healthcare system", should be in the spotlight
[@frohlich_hype_2018]. Synergies across a wide variety of existing
cohort integration projects could yield considerable benefits for
diverse scientific fields. In this sense, we expect the Synchros repository
to be a valuable resource for emerging collaborative health research.
Compared to undertaking new international mega-cohorts, integration of
existing cohorts may be more cost-effective [@larsen_pregnancy_2013].
One of the goals of Horizon Europe is to promote worldwide collaboration
with countries with strong investments in science [@abbott_how_2019].
The integration of cohort studies across these countries will certainly
drive us towards the longed-for scenario where we will be able
to highly improve the value of worldwide scientific data,
with the ultimate goal of maximizing health outcomes.
 
# References

::: {#refs}
:::

\newpage

<!---BLOCK_LANDSCAPE_START--->

# Tables

```{r initiatives, tab.id="initiatives", tab.cap="Descriptive information of the initiatives included in the mapping.", results='asis', cache=FALSE}
initiatives_table_output
```

<!---BLOCK_LANDSCAPE_STOP--->

\newpage

```{r descriptives, tab.id="descriptives", tab.cap="Descriptive statistics of the initiatives mapped.", results='asis', cache=FALSE}
descriptives_table_output
```

```{r reset-root-dir, cache=FALSE}
# Necessary for officedown to find the template file:
opts_knit$set(root.dir = ROOT_DIR)
```
